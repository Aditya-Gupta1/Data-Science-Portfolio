# -*- coding: utf-8 -*-
"""DogsVsCatsClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_87GntkM-KSkXplOacUewUXZiALsA6P_
"""

#Setting up Kaggle

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

#Downloading and Unzipping Data

!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition
!unzip dogs-vs-cats-redux-kernels-edition.zip
!unzip train.zip
# rm -r 'train'

#Checking if gpu is working fine.
import tensorflow as tf
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))
print(tf.test.gpu_device_name())
print(tf.config.experimental.list_physical_devices('GPU'))
tf.debugging.set_log_device_placement(True)
a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])
c = tf.matmul(a, b)
print(c)

#To check for tpu
# import tensorflow as tf
# import os
# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
# tf.config.experimental_connect_to_cluster(resolver)
# # This is the TPU initialization code that has to be at the beginning.
# tf.tpu.experimental.initialize_tpu_system(resolver)
# strategy = tf.distribute.experimental.TPUStrategy(resolver)

#looking the images
import matplotlib.pyplot as plt
from matplotlib.image import imread
folder = 'train/'
for i in range(9):
  plt.subplot(330+1+i)
  filename = folder+'cat.'+str(i)+'.jpg'
  image = imread(filename)
  plt.imshow(image)
plt.show()

"""#Organise Dataset Into Required Format"""

# organize dataset into a useful structure
from os import makedirs
from os import listdir
from shutil import copyfile
from random import seed
from random import random
import os

os.makedirs('test')

src_directory_files = os.listdir('train')

subdirs = ['train/', 'test/']
for subdir in subdirs:

	labeldirs = ['dogs/','cats/']
	for labldir in labeldirs:
		newdir = subdir + labldir
		makedirs(newdir)
	
seed(1)
val_ratio = 0.25
src_directory = 'train/'
for file in src_directory_files:
	src = src_directory + file
	dst_dir = 'train/'
	if random() < val_ratio:
		dst_dir = 'test/'
	if file.startswith('cat'):
		dst = dst_dir + 'cats/'  + file
		copyfile(src, dst)
	elif file.startswith('dog'):
		dst = dst_dir + 'dogs/'  + file
		copyfile(src, dst)
print('Number of Training Dogs images : {}'.format(len(os.listdir('train/dogs'))))
print('Number of Training Cats images : {}'.format(len(os.listdir('train/cats'))))
print('Number of Testing Dogs images : {}'.format(len(os.listdir('test/dogs'))))
print('Number of Testing Cats images : {}'.format(len(os.listdir('test/cats'))))

"""#Utility Functions

##Plotting Summary
"""

def summarize_diagnostics(history,plotname):
  import matplotlib.pyplot as plt
  print('\nPlots\n')

  plt.subplot(211)
  plt.title('CrossEntropy Loss')
  plt.plot(history.history['loss'],color= 'blue', label= 'train')
  plt.plot(history.history['val_loss'], color= 'orange', label= 'test')
  plt.legend()

  plt.subplot(212)
  plt.title('Classification Accuracy')
  plt.plot(history.history['accuracy'], color= 'blue', label= 'train')
  plt.plot(history.history['val_accuracy'], color= 'orange', label= 'test')
  plt.legend()

  plt.tight_layout()
  plt.savefig(plotname+'_plot.png')
  plt.show()
  plt.close()

"""##Final Function to fit the model"""

def run_test_harness(model):
  datagen = ImageDataGenerator(rescale= 1./255)

  print('\nInitializing Training Data Generator\n')
  train_data_gen = datagen.flow_from_directory('train',
                                               class_mode= 'binary',
                                               batch_size= 64,
                                               target_size= (200,200))
  
  print('\nInitializing Testing Data Generator\n')
  test_data_gen = datagen.flow_from_directory('test',
                                              class_mode= 'binary',
                                              batch_size= 64,
                                              target_size= (200,200))
  
  print('\nModel Fitting\n')
  history = model.fit_generator(train_data_gen,
                                steps_per_epoch= len(train_data_gen),
                                validation_data = test_data_gen,
                                validation_steps= len(test_data_gen),
                                epochs= 20
                                )
  
  print('\nEvaluating Model\n')
  _, acc = model.evaluate_generator(test_data_gen,
                                    steps= len(test_data_gen)
                                    )
  
  print('>%.3f'%(acc*100))

  return history

"""#One Block of VGG Architecture"""

#Function to define model
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Dense, Flatten
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator

def define_model_1():
  print('\nModel Initialization\n')
  model = Sequential([
                      Conv2D(32,(3,3),activation= 'relu', kernel_initializer= 'he_uniform', padding= 'same', input_shape=(200,200,3)),
                      MaxPool2D((2,2)),
                      Flatten(),
                      Dense(128, activation= 'relu', kernel_initializer= 'he_uniform'),
                      Dense(1, activation= 'sigmoid')
  ])
  print('\nModel Compilation\n')
  model.compile(optimizer= SGD(lr = 0.001, momentum= 0.9), loss = 'binary_crossentropy', metrics= ['accuracy'])
  return model

"""#Two Blocks of VGG architecture"""

#Function to define model
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Dense, Flatten
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator

def define_model_2():
  print('\nModel Initialization\n')
  model = Sequential([
                      Conv2D(32,(3,3),activation= 'relu', kernel_initializer= 'he_uniform', padding= 'same', input_shape=(200,200,3)),
                      MaxPool2D((2,2)),
                      Conv2D(64,(3,3),activation= 'relu', kernel_initializer= 'he_uniform', padding= 'same'),
                      MaxPool2D((2,2)),
                      Flatten(),
                      Dense(128, activation= 'relu', kernel_initializer= 'he_uniform'),
                      Dense(1, activation= 'sigmoid')
  ])
  print('\nModel Compilation\n')
  model.compile(optimizer= SGD(lr = 0.001, momentum= 0.9), loss = 'binary_crossentropy', metrics= ['accuracy'])

  return model

"""#Three blocks of vgg architecture"""

#Function to define model
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Dense, Flatten
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator

def define_model_3():
  print('\nModel Initialization\n')
  model = Sequential([
                      Conv2D(32,(3,3),activation= 'relu', kernel_initializer= 'he_uniform', padding= 'same', input_shape=(200,200,3)),
                      MaxPool2D((2,2)),
                      Conv2D(64,(3,3),activation= 'relu', kernel_initializer= 'he_uniform', padding= 'same'),
                      MaxPool2D((2,2)),
                      Conv2D(128,(3,3),activation= 'relu', kernel_initializer= 'he_uniform', padding= 'same'),
                      MaxPool2D((2,2)),
                      Flatten(),
                      Dense(128, activation= 'relu', kernel_initializer= 'he_uniform'),
                      Dense(1, activation= 'sigmoid')
  ])
  print('\nModel Compilation\n')
  model.compile(optimizer= SGD(lr = 0.001, momentum= 0.9), loss = 'binary_crossentropy', metrics= ['accuracy'])

  return model

"""#Evaluating all the models

##Model with one block vgg architecture
"""

model_1 = define_model_1()
print('Model Summary\n')
print(model_1.summary())
history_1 = run_test_harness(model_1)
summarize_diagnostics(history_1,'one_block_vgg_architecture')
model_1.save('one_block_vgg_architecture')

"""##Model with two blocks vgg architecture"""

model_2 = define_model_2()
print('Model Summary\n')
print(model_2.summary())
history_2 = run_test_harness(model_2)
summarize_diagnostics(history_2,'two_blocks_vgg_architecture')
model_2.save('two_blocks_vgg_architecture')

"""##Model with three blocks vgg architecture"""

model_3 = define_model_3()
print('Model Summary\n')
print(model_3.summary())
history_3 = run_test_harness(model_3)
summarize_diagnostics(history_3,'three_blocks_vgg_architecture')
model_3.save('three_blocks_vgg_architecture')

"""#Summary
We have 3 different architectures:
1. One block VGG Architecture - 74.504% Accuracy
2. Two blocks VGG Architecture - 76.598 Accuracy
3. Three blocks VGG Architecture - 79.280 Accuracy

It seems that all of the above three architectures start to overfit the training data at some point of training. To solve this problem, we can use regularization technique such as **Image Augmentation**. This will help the network to identify extra features from the image.

#Three block vgg architecture with Image Augmentation
"""

def run_test_harness_regularized(model):
  train_datagen = ImageDataGenerator(rescale= 1./255,
                               rotation_range= 45,
                               width_shift_range= 0.1,
                               height_shift_range= 0.1,
                               horizontal_flip= True
                               )
  test_datagen = ImageDataGenerator(rescale= 1./255)

  print('\nInitializing Training Data Generator\n')
  train_data_gen = train_datagen.flow_from_directory('train',
                                               class_mode= 'binary',
                                               batch_size= 64,
                                               target_size= (200,200))
  
  print('\nInitializing Testing Data Generator\n')
  test_data_gen = test_datagen.flow_from_directory('test',
                                              class_mode= 'binary',
                                              batch_size= 64,
                                              target_size= (200,200))
  
  print('\nModel Fitting\n')
  history = model.fit_generator(train_data_gen,
                                steps_per_epoch= len(train_data_gen),
                                validation_data = test_data_gen,
                                validation_steps= len(test_data_gen),
                                epochs= 50,
                                verbose= 1
                                )
  
  print('\nEvaluating Model\n')
  _, acc = model.evaluate_generator(test_data_gen,
                                    steps= len(test_data_gen)
                                    )
  
  print('>%.3f'%(acc*100))

  return history

model_3_regularized = define_model_3()
print('Model Summary\n')
print(model_3_regularized.summary())
history_regularized_3 = run_test_harness_regularized(model_3_regularized)
summarize_diagnostics(history_regularized_3,'three_block_regularized_vgg')
model_3_regularized.save('three_block_regularized_vgg')

"""#Transfer Learning using VGG-16 Pretrained Model"""

from keras.utils import to_categorical
from keras.applications.vgg16 import VGG16
from keras.models import Model
from keras.layers import Dense
from keras.layers import Flatten
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator

def define_vgg16_model():
  model = VGG16(include_top= False, input_shape= (224,224,3))
  for layer in model.layers:
    layer.trainable= False
  flat1 = Flatten()(model.layers[-1].output)
  class1 = Dense(128, activation= 'relu', kernel_initializer= 'he_uniform')(flat1)
  output = Dense(1,activation= 'sigmoid')(class1)

  model = Model(inputs= model.inputs, outputs= output)
  opt = SGD(lr= 0.001, momentum= 0.9)

  model.compile(optimizer= opt, loss= 'binary_crossentropy',metrics=['accuracy'])
  return model

def run_test_harness_vgg16(model):
  datagen = ImageDataGenerator(featurewise_center= True)
  datagen.mean = [123.68, 116.779, 103.939]

  print('\nInitializing Training Data Generator\n')
  train_data_gen = datagen.flow_from_directory('train',
                                               class_mode= 'binary',
                                               batch_size= 64,
                                               target_size= (224,224))
  
  print('\nInitializing Testing Data Generator\n')
  test_data_gen = datagen.flow_from_directory('test',
                                              class_mode= 'binary',
                                              batch_size= 64,
                                              target_size= (224,224))
  
  print('\nModel Fitting\n')
  history = model.fit_generator(train_data_gen,
                                steps_per_epoch= len(train_data_gen),
                                validation_data = test_data_gen,
                                validation_steps= len(test_data_gen),
                                epochs= 10
                                )
  
  print('\nEvaluating Model\n')
  _, acc = model.evaluate_generator(test_data_gen,
                                    steps= len(test_data_gen)
                                    )
  
  print('>%.3f'%(acc*100))

  return history

model_vgg16 = define_vgg16_model()
print('Model Summary\n')
print(model_vgg16.summary())
history_vgg16 = run_test_harness_vgg16(model_vgg16)
summarize_diagnostics(history_vgg16,'VGG16')

"""#Summary
Three block vgg architecture with Image Augmentation - 82.929% Accuracy<br>
VGG16 Pretrained Model - 97.985% Accuracy
"""